{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Wright-Fisher simulation implemented in C++ via Cython.\n",
    "\n",
    "This tutorial implements a Wright-Fisher simulation with mutation and recombination using [Cython](http://www.cython.org).  Cython is two things:\n",
    "\n",
    "* A grammer/dialect of Python that allows static typing Python and of C/C++ types.\n",
    "* A static compiler to turn the Cython grammer in to C or C++ code to compile into a Python extension module.\n",
    "\n",
    "Cython has a learning curve of its own. A lot of what is shown below reflects best practices.  For those, we refer you to the Cython documentation.\n",
    "\n",
    "Here, we avoid all use of [numpy](http://www.numpy.org) until we have to talk to [msprime](http://msprime.readthedocs.io).  We replace all numpy functionality with the equivalent routines from the excellent GNU Scientific Library, or [GSL](https://www.gnu.org/software/gsl/doc/html/index.html). Yes, numpy is fast!  Numpy is written in C!  But, numpy has to talk back and forth to Python, meaning we can out-perform it by writing routines that execute completely on the C side.\n",
    "\n",
    "This example is closer to reality for those working in lower-level languages.  First, we must build our world, which means defining data types (structs, in this case), functions acting on those types, and a bunch of auxillary code to manage memory and handle errors.  After all that, we can code up the `simplify` and `evolve` functions. Such is the price of speed.\n",
    "\n",
    "First, we load an extension allowing us to write Cython in a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "# Set ourselves up for some plotting, too\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --cplus --compile-args=-std=c++11 -3 -lgsl -lgslcblas -lm\n",
    "\n",
    "import msprime\n",
    "import numpy as np\n",
    "import struct\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "from cython.operator cimport dereference as deref\n",
    "from libc.stdint cimport int32_t, uint32_t\n",
    "from libcpp.vector cimport vector\n",
    "from libcpp.unordered_set cimport unordered_set\n",
    "from libcpp.utility cimport pair\n",
    "from cython_gsl.gsl_rng cimport *\n",
    "\n",
    "# Cython doesn't export all of C++'s standard library,\n",
    "# so we have to expose a few things we need:\n",
    "cdef extern from \"<algorithm>\" namespace \"std\" nogil:\n",
    "    Iter find[Iter,ValueType](Iter begin, Iter end, const ValueType & value)\n",
    "    Iter max_element[Iter](Iter begin, Iter end)\n",
    "    \n",
    "cdef cppclass TableData:\n",
    "    # Node data:\n",
    "    vector[double] time\n",
    "    # Edge data\n",
    "    vector[int32_t] parent, child\n",
    "    vector[double] left, right\n",
    "    # Mutation data\n",
    "    vector[double] pos\n",
    "    vector[int32_t] node, generation\n",
    "    \n",
    "    # lookup table to book-keep \n",
    "    # infinitely-many sites mutation\n",
    "    # model\n",
    "    unordered_set[double] mut_lookup\n",
    "    \n",
    "    TableData():\n",
    "        time.reserve(10000)\n",
    "        parent.reserve(10000)\n",
    "        child.reserve(10000)\n",
    "        left.reserve(10000)\n",
    "        right.reserve(10000)\n",
    "        pos.reserve(10000)\n",
    "        node.reserve(10000)\n",
    "        generation.reserve(10000)\n",
    "        \n",
    "    void clear():\n",
    "        time.clear()\n",
    "        parent.clear()\n",
    "        child.clear()\n",
    "        left.clear()\n",
    "        right.clear()\n",
    "        pos.clear()\n",
    "        node.clear()\n",
    "        generation.clear()\n",
    "        \n",
    "    @cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "    @cython.wraparound(False)  # turn off negative index wrapping for entire function\n",
    "    void reset_lookup(np.ndarray[double,ndim=1] pos):\n",
    "        mut_lookup.clear()\n",
    "        cdef size_t i=0\n",
    "        for i in range(len(pos)):\n",
    "            mut_lookup.insert(pos[i])\n",
    "        \n",
    "cdef pair[int32_t, int32_t] pick_parents(const gsl_rng *r, const int32_t N, const int32_t first_parental_index):\n",
    "    cdef pair[int32_t, int32_t] rv\n",
    "    cdef int32_t p = <int32_t>gsl_ran_flat(r,0.0,<double>N)\n",
    "    \n",
    "    rv.first = first_parental_index + 2*p\n",
    "    rv.second = rv.first+1\n",
    "    # \"Mendel\"\n",
    "    if gsl_rng_uniform(r) < 0.5:\n",
    "        rv.first, rv.second = rv.second, rv.first\n",
    "    return rv\n",
    "\n",
    "\n",
    "cdef void infsites(const gsl_rng *r, const double mu, \n",
    "             const int32_t offspring_node,\n",
    "             const int32_t generation,\n",
    "             TableData & tables):\n",
    "    cdef unsigned nmuts=gsl_ran_poisson(r,mu)\n",
    "    cdef size_t i\n",
    "    cdef double pos\n",
    "    for i in range(<size_t>nmuts):\n",
    "        pos = gsl_rng_uniform(r)\n",
    "        while tables.mut_lookup.find(pos)!=tables.mut_lookup.end():\n",
    "            pos = gsl_rng_uniform(r)\n",
    "        tables.mut_lookup.insert(pos)\n",
    "        tables.pos.push_back(pos)\n",
    "        tables.node.push_back(offspring_node)\n",
    "        tables.generation.push_back(generation)\n",
    "        \n",
    "cdef void simplify(TableData & tables, object nodes, object edges,\n",
    "                   object sites, object mutations,\n",
    "                   const double dt):\n",
    "    nodes.set_columns(time=nodes.time+dt,flags=nodes.flags)\n",
    "    \n",
    "    # Reverse new node times and add to nodes\n",
    "    cdef mtime = deref(max_element(tables.time.begin(),tables.time.end()))\n",
    "    #cdef double mtime = deref(mitr)\n",
    "    cdef size_t index=0\n",
    "    for index in range(tables.time.size()):\n",
    "        tables.time[index]=-1.0*(tables.time[index]-mtime)\n",
    "    nodes.append_columns(time=np.asarray(<double[:tables.time.size()]>tables.time.data()),\n",
    "                        flags=np.ones(tables.time.size(),dtype=np.uint32))\n",
    "    \n",
    "    edges.append_columns(left=np.asarray(<double[:tables.left.size()]>tables.left.data()),\n",
    "                        right=np.asarray(<double[:tables.right.size()]>tables.right.data()),\n",
    "                        parent=np.asarray(<int32_t[:tables.parent.size()]>tables.parent.data()),\n",
    "                        child=np.asarray(<int32_t[:tables.child.size()]>tables.child.data()))\n",
    "    for index in range(tables.pos.size()):\n",
    "        sites.add_row(position=tables.pos[index],\n",
    "                      ancestral_state=`0`)\n",
    "        mutations.add_row(site=len(sites)-1,\n",
    "                          node=tables.node[index],\n",
    "                         derived_state='1')\n",
    "        \n",
    "    \n",
    "    samples=np.where(nodes.time==0.0)[0]\n",
    "    msprime.sort_tables(nodes=nodes,edges=edges,sites=sites,\n",
    "                       mutations=mutations)\n",
    "    msprime.simplify_tables(samples=samples.tolist(),\n",
    "                           nodes=nodes,\n",
    "                           edges=edges,\n",
    "                           sites=sites,\n",
    "                           mutations=mutations)\n",
    "                            \n",
    "    tables.clear()\n",
    "    \n",
    "    \n",
    "def evolve(int N, int ngens, double theta, double rho, int gc, int seed):\n",
    "    nodes = msprime.NodeTable()\n",
    "    nodes.set_columns(time=np.zeros(2*N),flags=np.ones(2*N,dtype=np.uint32))\n",
    "    edges = msprime.EdgeTable()\n",
    "    sites = msprime.SiteTable()\n",
    "    mutations = msprime.MutationTable()\n",
    "    \n",
    "    \n",
    "    cdef double mu = theta/(4*<double>N)\n",
    "    cdef TableData tables\n",
    "    cdef gsl_rng * r = gsl_rng_alloc(gsl_rng_mt19937)\n",
    "    gsl_rng_set(r,seed)\n",
    "    cdef size_t generation=0,offspring=0\n",
    "    cdef int32_t next_offspring_index = 2*N #Same as len(nodes)\n",
    "    cdef int32_t first_parental_index = 0\n",
    "    \n",
    "    for generation in range(ngens):\n",
    "        for offspring in range(N):\n",
    "            parents1 = pick_parents(r,N,first_parental_index)\n",
    "            parents2 = pick_parents(r,N,first_parental_index)\n",
    "            tables.time.push_back(generation+1.0)\n",
    "            tables.time.push_back(generation+1.0)\n",
    "            \n",
    "            tables.left.push_back(0.0)\n",
    "            tables.right.push_back(1.0)\n",
    "            tables.parent.push_back(parents1.first)\n",
    "            tables.child.push_back(next_offspring_index)\n",
    "            infsites(r,mu,next_offspring_index,generation+1,tables)\n",
    "            \n",
    "            tables.left.push_back(0.0)\n",
    "            tables.right.push_back(1.0)\n",
    "            tables.parent.push_back(parents2.first)\n",
    "            tables.child.push_back(next_offspring_index+1)\n",
    "            infsites(r,mu,next_offspring_index+1,generation+1,tables)\n",
    "            next_offspring_index += 2\n",
    "        first_parental_index = next_offspring_index - 2*N\n",
    "        \n",
    "    print(tables.pos.size(),tables.mut_lookup.size())\n",
    "    simplify(tables,nodes,edges,sites,mutations,ngens)\n",
    "    gsl_rng_free(r)\n",
    "    \n",
    "    return msprime.load_tables(nodes=nodes,edges=edges,sites=sites,mutations=mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000008 1000008\n",
      "CPU times: user 16.7 s, sys: 4.22 s, total: 21 s\n",
      "Wall time: 21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<msprime.trees.TreeSequence at 0x11797d240>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "evolve(1000,20000,100,0,0,42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to msprime\n",
    "\n",
    "In this section, we compare the distribution of outputs to msprime using [pylibseq](https://github.com/molpopgen/pylibseq), a Python interface to [libsequence](http://molpopgen.github.io/libsequence/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "import msprime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from libsequence.polytable import SimData\n",
    "from libsequence.summstats import PolySIM\n",
    "from libsequence.msprime import make_SimData\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "SummStats=namedtuple('SummStats',['S','pi','D','hprime','rmin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick tour of pylibseq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//\n",
      "segsites: 10\n",
      "positions: 0.26833 0.290974 0.325691 0.349762 0.369596 0.390163 0.583813 0.743047 0.767412 0.978347\n",
      "0100100100\n",
      "1000010000\n",
      "0010001000\n",
      "0100100100\n",
      "0001100100\n",
      "0000100101\n",
      "0000100110\n",
      "1000010000\n",
      "1000010000\n",
      "0100100100\n"
     ]
    }
   ],
   "source": [
    "# Simulate data with msprime\n",
    "ts = msprime.simulate(10,mutation_rate=1,random_seed=666)\n",
    "\n",
    "# Get it into the format expected by pylibseq\n",
    "d = make_SimData(ts)\n",
    "\n",
    "# This should look familiar! :)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4666666666666672 -0.08550572842849505 0.5368222463065044 0\n"
     ]
    }
   ],
   "source": [
    "# Create object to calculate summary stats\n",
    "x = PolySIM(d)\n",
    "# Calculate a few:\n",
    "print(x.thetapi(),x.tajimasd(),x.hprime(),x.rm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.2 s, sys: 11.6 ms, total: 5.21 s\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "msprime_raw_data=[]\n",
    "for i in msprime.simulate(10,mutation_rate=100.0/4.0,\n",
    "                          recombination_rate=0.0,\n",
    "                          num_replicates=1000,\n",
    "                          random_seed=42):\n",
    "    d = make_SimData(i)\n",
    "    ps = PolySIM(d)\n",
    "    # A little check that the two pieces of code agree\n",
    "    assert(ps.numpoly() == i.num_mutations)\n",
    "    msprime_raw_data.append(SummStats(ps.numpoly(),\n",
    "                                      ps.thetapi(),ps.tajimasd(),\n",
    "                                      ps.hprime(),ps.rm()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the forward simulations, we will use multiple Python processes via Python 3's [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html) library. The short of it is that we need a Python function to send out to different processes and return results, which will be pickled into a future back in the main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forward_sim(nreps,seed,repid):\n",
    "    \"\"\"\n",
    "    Run our forward sim, calculate\n",
    "    a bunch of stats, and return \n",
    "    the list.\n",
    "    \"\"\"\n",
    "    # Not the best seeding scheme, \n",
    "    # but good enough for now...\n",
    "    np.random.seed(seed)\n",
    "    msp_rng = msprime.RandomGenerator(int(seed))\n",
    "    seeds = np.random.randint(0,1000000,nreps)\n",
    "    sims = []\n",
    "    for i in range(nreps):\n",
    "        # print('inputs:',repid,seeds[i])\n",
    "        ts = evolve(500,10000,100.0,0.0,500,seeds[i])\n",
    "        samples = np.random.choice(1000,10,replace=False)\n",
    "        assert(all(ts.tables.nodes.time[samples]==0.0))\n",
    "        ts2 = ts.simplify(samples=samples.tolist())\n",
    "        # n=msprime.NodeTable()\n",
    "        # e=msprime.EdgeTable()\n",
    "        # s=msprime.SiteTable()\n",
    "        # m=msprime.MutationTable()\n",
    "        # ts2.dump_tables(nodes=n,edges=e)\n",
    "        # print(n.time.max())\n",
    "        # mutgen = msprime.MutationGenerator(\n",
    "        #     msp_rng, 100.0/(float(4*500)))\n",
    "        # mutgen.generate(n,e,s,m)\n",
    "        # ts2=msprime.load_tables(nodes=n,edges=e,sites=s,mutations=m)\n",
    "        # print(samples)\n",
    "        # print(n.time[samples])\n",
    "        # print(s)\n",
    "        # print(m)\n",
    "        # Simplify from entire pop down\n",
    "        # to random sample of n << 2N\n",
    "        # slist = samples.tolist()\n",
    "        # slist.append(8)\n",
    "        # ts2=ts.simplify(slist)\n",
    "        # print(ts2.num_mutations)\n",
    "        # print(len(ts2.tables.nodes),\n",
    "        #      len(ts2.tables.edges),\n",
    "        #      len(ts2.tables.sites),\n",
    "        #      len(ts2.tables.mutations))\n",
    "        d=make_SimData(ts2)\n",
    "        ps=PolySIM(d)\n",
    "        sims.append(SummStats(ps.numpoly(),\n",
    "                              ps.thetapi(),\n",
    "                              ps.tajimasd(),\n",
    "                              ps.hprime(),\n",
    "                              ps.rm()))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499259 499259\n",
      "[SummStats(S=525, pi=214.31111111111005, D=0.7758200022046403, hprime=0.6332319801973835, rmin=0)]\n",
      "CPU times: user 4.8 s, sys: 1.12 s, total: 5.92 s\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x=run_forward_sim(1,66,3511)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next bit, we map our function into four separate processes.\n",
    "\n",
    "**Note:** We could use a `concurrent.futures.ThreadPoolExecutor` instead of the process pool executor.  However, some of our Cython functions rely on Python types (`list`, `dict`, etc.), meaning that the Global Interpreter Lock is a barrier to efficient concurrency.  In practice, we've found it better to take the hit of pickling between processes so that your simulations can run at 100% CPU in different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500497 500497\n",
      "498934 498934\n",
      "500517 500517\n",
      "500799 500799\n",
      "500257 500257\n",
      "499961 499961\n",
      "499775 499775\n",
      "499155 499155\n",
      "498239 498239\n",
      "498899 498899\n",
      "499763 499763\n",
      "498240 498240\n",
      "499459 499459\n",
      "499648 499648\n",
      "499439 499439\n",
      "498961 498961\n",
      "500314 500314\n",
      "498829 498829\n",
      "499518 499518\n",
      "500138 500138\n",
      "500281 500281\n",
      "499355 499355\n",
      "498454 498454\n",
      "499630 499630\n",
      "500590 500590\n",
      "499668 499668\n",
      "498875 498875\n",
      "500088 500088\n",
      "500454 500454\n",
      "500876 500876\n",
      "500486 500486\n",
      "500072 500072\n",
      "499828 499828\n",
      "500521 500521\n",
      "501162 501162\n",
      "500808 500808\n",
      "500386 500386\n",
      "500637 500637\n",
      "501606 501606\n",
      "499688 499688\n",
      "499794 499794\n",
      "501109 501109\n",
      "499888 499888\n",
      "500332 500332\n",
      "499586 499586\n",
      "499150 499150\n",
      "499929 499929\n",
      "499360 499360\n",
      "500265 500265\n",
      "501072 501072\n",
      "499559 499559\n",
      "500453 500453\n",
      "500212 500212\n",
      "500977 500977\n",
      "501143 501143\n",
      "500878 500878\n",
      "500392 500392\n",
      "499591 499591\n",
      "499428 499428\n",
      "499370 499370\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fwd_sim_data=[]\n",
    "np.random.seed(16463623)\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    futures = {executor.submit(run_forward_sim,50,np.random.randint(0,2000000,1)[0],i): i for i in range(4)}\n",
    "    for fut in concurrent.futures.as_completed(futures):\n",
    "        fn = fut.result()\n",
    "        fwd_sim_data.extend(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msprime_df = pd.DataFrame(msprime_raw_data)\n",
    "msprime_df['engine'] = ['msprime']*len(msprime_df.index)\n",
    "fwd_df = pd.DataFrame(fwd_sim_data)\n",
    "fwd_df['engine']=['forward']*len(fwd_df)\n",
    "summstats_df = pd.concat([msprime_df,fwd_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.FacetGrid(summstats_df,col=\"engine\",margin_titles=True)\n",
    "bins = np.linspace(summstats_df.pi.min(),summstats_df.pi.max(),20)\n",
    "g.map(plt.hist,'pi',bins=bins,color=\"steelblue\",lw=0,normed=True);\n",
    "\n",
    "g = sns.FacetGrid(summstats_df,col=\"engine\",margin_titles=True)\n",
    "bins = np.linspace(summstats_df.S.min(),summstats_df.S.max(),20)\n",
    "g.map(plt.hist,'S',bins=bins,color=\"steelblue\",lw=0,normed=True);\n",
    "\n",
    "g = sns.FacetGrid(summstats_df,col=\"engine\",margin_titles=True)\n",
    "bins = np.linspace(summstats_df.D.min(),summstats_df.D.max(),20)\n",
    "g.map(plt.hist,'D',bins=bins,color=\"steelblue\",lw=0,normed=True);\n",
    "\n",
    "g = sns.FacetGrid(summstats_df,col=\"engine\",margin_titles=True)\n",
    "bins = np.linspace(summstats_df.rmin.min(),summstats_df.rmin.max(),20)\n",
    "g.map(plt.hist,'rmin',bins=bins,color=\"steelblue\",lw=0,normed=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fwd_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summstats_df.groupby(['engine']).agg(['mean','std']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats are clearly off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.pi,msprime_df.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.S,msprime_df.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.D,msprime_df.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.rmin,msprime_df.rmin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
