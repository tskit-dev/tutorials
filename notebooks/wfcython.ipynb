{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Wright-Fisher simulation implemented in C via Cython.\n",
    "\n",
    "This tutorial implements a Wright-Fisher simulation with mutation and recombination using [Cython](http://www.cython.org).  Cython is two things:\n",
    "\n",
    "* A grammer/dialect of Python that allows static typing Python and of C/C++ types.\n",
    "* A static compiler to turn the Cython grammer in to C or C++ code to compile into a Python extension module.\n",
    "\n",
    "Cython has a learning curve of its own. A lot of what is shown below reflects best practices.  For those, we refer you to the Cython documentation.\n",
    "\n",
    "Here, we avoid all use of [numpy](http://www.numpy.org) until we have to talk to [msprime](http://msprime.readthedocs.io).  We replace all numpy functionality with the equivalent routines from the excellent GNU Scientific Library, or [GSL](https://www.gnu.org/software/gsl/doc/html/index.html). Yes, numpy is fast!  Numpy is written in C!  But, numpy has to talk back and forth to Python, meaning we can out-perform it by writing routines that execute completely on the C side.\n",
    "\n",
    "This example is closer to reality for those working in lower-level languages.  First, we must build our world, which means defining data types (structs, in this case), functions acting on those types, and a bunch of auxillary code to manage memory and handle errors.  After all that, we can code up the `simplify` and `evolve` functions. Such is the price of speed.\n",
    "\n",
    "First, we load an extension allowing us to write Cython in a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "# Set ourselves up for some plotting, too\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block is our Cython code.  The notebook environment will magically compile it from Cython to C, from C to a compiled Python module, and load the module into memory.\n",
    "\n",
    "The code block is unavoidably long.  It defines a single Python function called `evolve`, which may then be run later in the notebook.  All of the functions marked `cdef` are visible only as C functions by other functions within the module.  This limited function scope is why we must write everything in one giant block.\n",
    "\n",
    "Some comments:\n",
    "\n",
    "* We use [CythonGSL](https://github.com/twiecki/CythonGSL) to get access to GSL types and functions in Cython.  Conda or pip install it if you want to use it for your projects.\n",
    "* The memory managment and error handling on the C side is minimal, and the error handling in particular is naive.\n",
    "* The recombination function is 100% executed in C.  Mutation is very close to that, except for where we use the `dict` to manage the infinitely-many sites mutation model.\n",
    "* We get copy-free transfer (I think...) from C to numpy arrays via Cython's typed memory views.\n",
    "* The `cimport` commands below bring names into scope. It is considered best practice to only `cimport` the symbols you use, but that quickly gets tedious here, and I gave myself a break and imported everything from `gsl_vector`.\n",
    "\n",
    "Some details:\n",
    "\n",
    "For reasons I don't understand, attempting to pickle a `collections.namedtuple` instance in a `cdef` function raises an exception.  The workaround is a Cython class decorated with `\\@cython.auto_pickle(True)`.  A side-effect is that the semantics for un-pickling the metadata differ from our Python examples.  Clearly, metadata is one of the trickier corners of `msprime/tskit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -3 -lgsl -lgslcblas -lm\n",
    "\n",
    "import msprime\n",
    "import numpy as np\n",
    "import struct\n",
    "cimport numpy as np\n",
    "from cython.view cimport array as cvarray\n",
    "from libc.stdlib cimport malloc, realloc, free\n",
    "from libc.stdint cimport int32_t, uint32_t\n",
    "\n",
    "from cython_gsl.gsl_rng cimport gsl_rng\n",
    "from cython_gsl.gsl_rng cimport gsl_rng_mt19937\n",
    "from cython_gsl.gsl_rng cimport gsl_rng_alloc\n",
    "from cython_gsl.gsl_rng cimport gsl_rng_free\n",
    "from cython_gsl.gsl_rng cimport gsl_rng_set\n",
    "from cython_gsl.gsl_rng cimport gsl_rng_uniform\n",
    "from cython_gsl.gsl_random cimport gsl_ran_flat\n",
    "from cython_gsl.gsl_random cimport gsl_ran_poisson\n",
    "from cython_gsl.gsl_vector cimport *\n",
    "from cython_gsl.gsl_sort cimport gsl_sort_vector\n",
    "\n",
    "cdef int32_t * malloc_int32_t(size_t n):\n",
    "    return <int32_t*>malloc(n*sizeof(int32_t))\n",
    "\n",
    "cdef int32_t * realloc_int32_t(void * x, size_t n):\n",
    "    return <int32_t*>realloc(x,n*sizeof(int32_t))\n",
    "\n",
    "cdef double * malloc_double(size_t n):\n",
    "    return <double*>malloc(n*sizeof(double))\n",
    "\n",
    "cdef double * realloc_double(double * x, size_t n):\n",
    "    return <double*>realloc(<double *>x,n*sizeof(double))\n",
    "\n",
    "cdef struct Mutations:\n",
    "    double * pos\n",
    "    int32_t * time\n",
    "    int32_t * node\n",
    "    size_t next_mutation, capacity\n",
    "    \n",
    "cdef int init_Mutations(Mutations * m):\n",
    "    m.next_mutation = 0\n",
    "    m.capacity = 10000\n",
    "    m.pos = malloc_double(m.capacity)\n",
    "    if m.pos == NULL:\n",
    "        return -1\n",
    "    m.time = malloc_int32_t(m.capacity)\n",
    "    if m.time == NULL:\n",
    "        return -1\n",
    "    m.node = malloc_int32_t(m.capacity)\n",
    "    if m.node == NULL:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "cdef int realloc_Mutations(Mutations * m):\n",
    "    m.capacity *= 2\n",
    "    m.pos = realloc_double(m.pos,\n",
    "                          m.capacity)\n",
    "    if m.pos == NULL:\n",
    "        return -1\n",
    "    m.time = realloc_int32_t(m.time,\n",
    "                            m.capacity)\n",
    "    if m.time == NULL:\n",
    "        return -1\n",
    "    m.node = realloc_int32_t(m.node,\n",
    "                            m.capacity)\n",
    "    if m.node == NULL:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "cdef void free_Mutations(Mutations * m):\n",
    "    free(m.pos)\n",
    "    free(m.time)\n",
    "    free(m.node)\n",
    "    m.next_mutation = 0\n",
    "    m.capacity = 10000\n",
    "    \n",
    "cdef int add_mutation(double pos,\n",
    "                     int32_t generation,\n",
    "                     int32_t node,\n",
    "                     list metadata,\n",
    "                     Mutations * m):\n",
    "    cdef int rv = 0\n",
    "    if m.next_mutation+1 >= m.capacity:\n",
    "        rv = realloc_Mutations(m)\n",
    "        if rv != 0:\n",
    "            return rv\n",
    "    m.pos[m.next_mutation] = pos\n",
    "    m.time[m.next_mutation] = generation\n",
    "    m.node[m.next_mutation] = node\n",
    "    m.next_mutation+=1\n",
    "    metadata.append(struct.pack('id',generation,pos))\n",
    "    return rv\n",
    "    \n",
    "cdef struct Nodes:\n",
    "    double * time\n",
    "    size_t next_node, capacity\n",
    "    \n",
    "cdef int init_Nodes(Nodes * n):\n",
    "    n.next_node = 0\n",
    "    n.capacity = 10000\n",
    "    n.time = malloc_double(n.capacity)\n",
    "    if n.time == NULL:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "cdef int realloc_Nodes(Nodes * n):\n",
    "    n.capacity *= 2\n",
    "    n.time = realloc_double(n.time,\n",
    "                            n.capacity)\n",
    "    if n.time == NULL:\n",
    "        return -1\n",
    "    return 0\n",
    "    \n",
    "cdef void free_Nodes(Nodes * n):\n",
    "    if n.time != NULL:\n",
    "        free(n.time)\n",
    "    n.next_node = 0\n",
    "    n.capacity = 10000\n",
    "\n",
    "cdef int add_node(double t, Nodes *n):\n",
    "    cdef int rv = 0\n",
    "    if n.next_node >= n.capacity:\n",
    "        rv = realloc_Nodes(n)\n",
    "        if rv != 0:\n",
    "            return rv\n",
    "    n.time[n.next_node] = t\n",
    "    n.next_node+=1\n",
    "    return rv\n",
    "    \n",
    "cdef struct Edges:\n",
    "    double *left\n",
    "    double *right\n",
    "    int32_t *parent\n",
    "    int32_t *child\n",
    "    size_t next_edge, capacity\n",
    "    \n",
    "cdef int init_Edges(Edges * e):\n",
    "    e.next_edge = 0\n",
    "    e.capacity = 10000\n",
    "    e.left = malloc_double(e.capacity)\n",
    "    if e.left == NULL:\n",
    "        return -1\n",
    "    e.right = malloc_double(e.capacity)\n",
    "    if e.right == NULL:\n",
    "        return -1\n",
    "    e.parent = malloc_int32_t(e.capacity)\n",
    "    if e.parent == NULL:\n",
    "        return -1\n",
    "    e.child = malloc_int32_t(e.capacity)\n",
    "    if e.child == NULL:\n",
    "        return -1\n",
    "    return 0\n",
    "   \n",
    "cdef int realloc_Edges(Edges * e):\n",
    "    e.capacity *= 2\n",
    "    e.left = realloc_double(e.left,e.capacity)\n",
    "    if e.left == NULL:\n",
    "        return -1\n",
    "    e.right = realloc_double(e.right,e.capacity)\n",
    "    if e.right == NULL:\n",
    "        return -1\n",
    "    e.parent = realloc_int32_t(e.parent,e.capacity)\n",
    "    if e.parent == NULL:\n",
    "        return -1\n",
    "    e.child = realloc_int32_t(e.child,e.capacity)\n",
    "    if e.child == NULL:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "cdef void free_Edges(Edges * e):\n",
    "    free(e.left)\n",
    "    free(e.right)\n",
    "    free(e.parent)\n",
    "    free(e.child)\n",
    "    e.next_edge = 0\n",
    "    e.capacity = 10000\n",
    "    \n",
    "cdef int add_edge(double left, double right,\n",
    "             int32_t parent, int32_t child,\n",
    "             Edges * edges):\n",
    "    cdef int rv=0\n",
    "    if edges.next_edge+1 >= edges.capacity:\n",
    "        rv = realloc_Edges(edges)\n",
    "        if rv != 0:\n",
    "            return rv\n",
    "        \n",
    "    edges.left[edges.next_edge] = left\n",
    "    edges.right[edges.next_edge] = right\n",
    "    edges.parent[edges.next_edge] = parent\n",
    "    edges.child[edges.next_edge] = child\n",
    "    edges.next_edge += 1\n",
    "    return rv\n",
    "\n",
    "cdef struct Tables:\n",
    "    Nodes nodes\n",
    "    Edges edges\n",
    "    Mutations mutations\n",
    "    gsl_rng * rng\n",
    "    \n",
    "cdef int init_Tables(Tables * t, int seed):\n",
    "    cdef int rv = 0\n",
    "    rv = init_Nodes(&t.nodes)\n",
    "    if rv != 0:\n",
    "        return rv\n",
    "    rv = init_Edges(&t.edges)\n",
    "    if rv != 0:\n",
    "        return rv\n",
    "    rv = init_Mutations(&t.mutations)\n",
    "    if rv != 0:\n",
    "        return rv\n",
    "    t.rng = gsl_rng_alloc(gsl_rng_mt19937)\n",
    "    if t.rng == NULL:\n",
    "        return -1\n",
    "    gsl_rng_set(t.rng, seed)\n",
    "    return rv\n",
    "\n",
    "cdef void free_Tables(Tables * t):\n",
    "    free_Nodes(&t.nodes)\n",
    "    free_Edges(&t.edges)\n",
    "    free_Mutations(&t.mutations)\n",
    "    gsl_rng_free(t.rng)\n",
    "    \n",
    "cdef int infsites(double mu, int32_t generation,\n",
    "                  int32_t next_offspring_index,\n",
    "                  Tables * tables,\n",
    "                  list metadata,\n",
    "                  dict lookup):\n",
    "    cdef unsigned nmut = gsl_ran_poisson(tables.rng, mu)\n",
    "    cdef unsigned i = 0\n",
    "    cdef double pos\n",
    "    cdef int rv = 0\n",
    "    for i in range(nmut):\n",
    "        pos = gsl_rng_uniform(tables.rng)\n",
    "        while pos in lookup:\n",
    "            pos = gsl_rng_uniform(tables.rng)\n",
    "        rv = add_mutation(pos,\n",
    "                         generation,\n",
    "                         next_offspring_index,\n",
    "                         metadata,\n",
    "                         &tables.mutations)\n",
    "        if rv != 0:\n",
    "            return rv\n",
    "        lookup[pos] = True\n",
    "    return rv\n",
    "\n",
    "cdef int value_present_vector(gsl_vector * v, double x,\n",
    "                              size_t start, size_t stop):\n",
    "    cdef size_t i\n",
    "    for i in range(start,stop):\n",
    "        if gsl_vector_get(v,i)==x:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "cdef int poisson_recombination(double r,\n",
    "                               size_t pg1, size_t pg2,\n",
    "                               int32_t next_offspring_id,\n",
    "                               Tables * tables):\n",
    "    cdef unsigned nbreaks = gsl_ran_poisson(tables.rng, r)\n",
    "    cdef gsl_vector * b = NULL\n",
    "    cdef unsigned i = 0#,drew_zero=0\n",
    "    cdef double x\n",
    "    cdef int rv = 0\n",
    "    cdef double left,right\n",
    "    cdef int32_t p\n",
    "    if nbreaks == 0:\n",
    "        # The parent passes the \n",
    "        # entire region onto the child\n",
    "        rv = add_edge(0.0,1.0,pg1,\n",
    "                      next_offspring_id,\n",
    "                      &tables.edges)\n",
    "        if rv != 0:\n",
    "            return rv\n",
    "    else:\n",
    "        b = gsl_vector_calloc(nbreaks+2) \n",
    "        while i < nbreaks:\n",
    "            x = gsl_rng_uniform(tables.rng)\n",
    "            while value_present_vector(b,x,0,i)==1:\n",
    "                x = gsl_rng_uniform(tables.rng)\n",
    "            gsl_vector_set(b,i,x)\n",
    "            i += 1\n",
    "        if gsl_vector_get(b,0) == 0.0:\n",
    "            pg1,pg2 = pg2,pg1\n",
    "            # We already have a zero\n",
    "            # in there, so we need\n",
    "            # to adjust size so that the \n",
    "            # 1.0 we insert below goes \n",
    "            # into the right place\n",
    "            b.size -= 1\n",
    "        else:\n",
    "            # shift all values by 1\n",
    "            # index and set element\n",
    "            # 0 to 0\n",
    "            # for i in range(b.size):\n",
    "            #     print(gsl_vector_get(b,i))\n",
    "            # print(\"-----\")\n",
    "            for i in range(b.size-1,0,-1):\n",
    "                gsl_vector_set(b,i,\n",
    "                              gsl_vector_get(b,i-1))\n",
    "            gsl_vector_set(b,0,0.0)\n",
    "                \n",
    "        gsl_vector_set(b,b.size-1,1.0)\n",
    "        gsl_sort_vector(b)\n",
    "        # print(\"nbreaks=\",nbreaks)\n",
    "        # for i in range(b.size):\n",
    "        #     print(gsl_vector_get(b,i))\n",
    "        # print(\"//\")\n",
    "        # if drew_zero == 1:\n",
    "        #     pg1,pg2 = pg2,pg1\n",
    "        for i in range(b.size-1):\n",
    "            left = gsl_vector_get(b,i)\n",
    "            right = gsl_vector_get(b,i+1)\n",
    "            rv = add_edge(left,right,pg1,\n",
    "                          next_offspring_id,\n",
    "                          &tables.edges)\n",
    "            if rv != 0:\n",
    "                gsl_vector_free(b)\n",
    "                return rv\n",
    "            pg1,pg2 = pg2,pg1\n",
    "    gsl_vector_free(b)\n",
    "    return 0\n",
    "\n",
    "cdef int make_offspring(double mu, double r,\n",
    "                        size_t generation,\n",
    "                        size_t pg1, size_t pg2,\n",
    "                        int32_t next_offspring_index,\n",
    "                        list metadata,\n",
    "                        dict lookup,\n",
    "                        Tables * tables):\n",
    "    cdef int rv\n",
    "    rv = poisson_recombination(r,pg1,pg2,\n",
    "                               next_offspring_index,\n",
    "                               tables)\n",
    "    if rv != 0:\n",
    "        return -2\n",
    "                \n",
    "    rv = infsites(mu,generation+1,\n",
    "                  next_offspring_index,\n",
    "                  tables,metadata,lookup)\n",
    "    if rv != 0:\n",
    "        return -3\n",
    "            \n",
    "    rv = add_node(generation+1, &tables.nodes)\n",
    "    if rv != 0:\n",
    "        return -4\n",
    "   \n",
    "    return 0\n",
    "\n",
    "cdef void handle_error_code(int error, Tables * tables):\n",
    "    \"\"\"\n",
    "    Only to be called after make_offspring\n",
    "    \"\"\"\n",
    "    if error == 0:\n",
    "        return\n",
    "    print(\"Error occurred\")\n",
    "    free_Tables(tables)\n",
    "    if error == -2:\n",
    "        raise RuntimeError(\"error during recombination\")\n",
    "    elif error == -2:\n",
    "        raise RuntimeError(\"error during mutation\")\n",
    "    elif error == -4:\n",
    "        raise RuntimeError(\"erorr adding nodes\")\n",
    "    else:\n",
    "        raise ValueError(\"invalid error code\")\n",
    "\n",
    "cdef int simplify(Tables * tables, \n",
    "            double dt,\n",
    "            list metadata,\n",
    "            object nodes,\n",
    "            object edges,\n",
    "            object sites,\n",
    "            object mutations):\n",
    "    cdef int rv = 0,gap\n",
    "    \n",
    "    cdef size_t i\n",
    "    cdef np.ndarray[double,ndim=1] dview,lview,rview\n",
    "    cdef np.ndarray[int32_t,ndim=1] pview,cview\n",
    "    # Reverse time for our new nodes\n",
    "    cdef gsl_vector_view vt\n",
    "    vt = gsl_vector_view_array(tables.nodes.time,<size_t>tables.nodes.next_node)\n",
    "    cdef double tmax,tmin\n",
    "    gsl_vector_minmax(&vt.vector,&tmin,&tmax)\n",
    "    for i in range(tables.nodes.next_node):\n",
    "        tables.nodes.time[i] = -1.0*(tables.nodes.time[i]-tmax)\n",
    "    gsl_vector_minmax(&vt.vector,&tmin,&tmax)\n",
    "    \n",
    "    nodes.set_columns(time=nodes.time+dt,flags=nodes.flags)\n",
    "    gap=nodes.time.min()-tmax\n",
    "    if gap != 1:\n",
    "        return -1\n",
    "    dview = np.asarray(<double[:tables.nodes.next_node]>tables.nodes.time)\n",
    "    nodes.append_columns(time=dview,\n",
    "                        flags=np.ones(tables.nodes.next_node,dtype=np.uint32))\n",
    "    \n",
    "    \n",
    "    lview = np.asarray(<double[:tables.edges.next_edge]>tables.edges.left)\n",
    "    rview = np.asarray(<double[:tables.edges.next_edge]>tables.edges.right)\n",
    "    pview = np.asarray(<int32_t[:tables.edges.next_edge]>tables.edges.parent)\n",
    "    cview = np.asarray(<int32_t[:tables.edges.next_edge]>tables.edges.child)\n",
    "    edges.append_columns(left=lview,\n",
    "                        right=rview,\n",
    "                        parent=pview,\n",
    "                        child=cview)\n",
    "    \n",
    "    # We are trying to be as fast as possible here,\n",
    "    # so we'll use the more cumbersome \n",
    "    # append_columns interface instead of the \n",
    "    # much slower (but easier to understand)\n",
    "    # add_rows\n",
    "    cdef size_t nsites = len(sites)\n",
    "    if tables.mutations.next_mutation > 0:\n",
    "        encoded, offset = msprime.pack_bytes(metadata)\n",
    "        dview = np.asarray(<double[:tables.mutations.next_mutation]>tables.mutations.pos)\n",
    "        sites.append_columns(position=dview,\n",
    "                            ancestral_state=np.zeros(len(dview),dtype=np.int8)+ord('0'),\n",
    "                            ancestral_state_offset=np.arange(len(dview)+1,dtype=np.uint32))\n",
    "        pview = np.asarray(<int32_t[:tables.mutations.next_mutation]>tables.mutations.node)\n",
    "        mutations.append_columns(site=np.arange(tables.mutations.next_mutation,\n",
    "                                                dtype=np.int32)+nsites,\n",
    "                                node=pview,\n",
    "                                derived_state=np.ones(len(dview),\n",
    "                                                      dtype=np.int8)+ord('0'),\n",
    "                                derived_state_offset=np.arange(len(dview)+1,\n",
    "                                                              dtype=np.uint32),\n",
    "                                metadata_offset=offset, metadata=encoded\n",
    "                                )\n",
    "    \n",
    "    msprime.sort_tables(nodes=nodes,edges=edges,\n",
    "                       sites=sites,mutations=mutations)\n",
    "    \n",
    "    samples = np.where(nodes.time == 0)[0]\n",
    "    msprime.simplify_tables(samples=samples.tolist(),\n",
    "                            nodes=nodes,\n",
    "                            edges=edges,\n",
    "                            sites=sites,\n",
    "                            mutations=mutations)\n",
    "    \n",
    "    # \"clear\" our temp containers\n",
    "    tables.nodes.next_node = 0\n",
    "    tables.mutations.next_mutation = 0\n",
    "    tables.edges.next_edge = 0\n",
    "                          \n",
    "    return rv\n",
    "\n",
    "def evolve(int N, int ngens, double theta, double rho, int gc, int seed):\n",
    "    nodes = msprime.NodeTable()\n",
    "    edges = msprime.EdgeTable()\n",
    "    sites = msprime.SiteTable()\n",
    "    mutations = msprime.MutationTable()\n",
    "    \n",
    "    cdef double mu = theta/<double>(4*N)\n",
    "    cdef double r = rho/<double>(4*N)\n",
    "    \n",
    "    cdef int rv\n",
    "    cdef size_t i, generation\n",
    "    cdef Tables tables\n",
    "    rv = init_Tables(&tables, seed)\n",
    "    if rv != 0:\n",
    "        free_Tables(&tables)\n",
    "        raise RuntimeError(\"could not initialize tables\")\n",
    "        \n",
    "    for i in range(2*<size_t>N):\n",
    "        nodes.add_row(time=0.0,\n",
    "                      flags=msprime.NODE_IS_SAMPLE)\n",
    "        \n",
    "    cdef int32_t next_offspring_index, first_parental_index\n",
    "    next_offspring_index = len(nodes)\n",
    "    first_parental_index = 0\n",
    "    cdef size_t parent1, parent2,pindex\n",
    "    cdef int32_t p1g1, p1g2, p2g1, p2g2\n",
    "    cdef dict lookup = {}\n",
    "    cdef list metadata = []\n",
    "    cdef size_t last_gen_gc = 0\n",
    "    for generation in range(<size_t>(ngens)):\n",
    "        if generation>0 and generation%gc == 0.0:\n",
    "            rv = simplify(&tables,\n",
    "                         generation-last_gen_gc,\n",
    "                         metadata,\n",
    "                         nodes,edges,sites,mutations)\n",
    "            if rv != 0:\n",
    "                free_Tables(&tables)\n",
    "                raise RuntimeError(\"simplification error\")\n",
    "            lookup = {spos:True for spos in sites.position}\n",
    "            # print(sites.position)\n",
    "            # print(lookup)\n",
    "            # print(\"lookup reset to\",len(lookup),len(sites))\n",
    "            metadata.clear()\n",
    "            last_gen_gc=generation\n",
    "            next_offspring_index = len(nodes)\n",
    "            first_parental_index = 0\n",
    "        else:\n",
    "            first_parental_index = next_offspring_index - 2*N\n",
    "            \n",
    "        for pindex in range(0,2*N,2):\n",
    "            parent1=<size_t>gsl_ran_flat(tables.rng,0.0,<double>N)\n",
    "            parent2=<size_t>gsl_ran_flat(tables.rng,0.0,<double>N)\n",
    "            p1g1 = first_parental_index + 2*parent1\n",
    "            p1g2 = p1g1 + 1\n",
    "            p2g1 = first_parental_index + 2*parent2\n",
    "            p2g2 = p2g1 + 1\n",
    "            \n",
    "            if gsl_rng_uniform(tables.rng) < 0.5:\n",
    "                p1g1, p1g2 = p1g2, p1g1\n",
    "            if gsl_rng_uniform(tables.rng) < 0.5:\n",
    "                p2g1, p2g2 = p2g2, p2g1\n",
    "                \n",
    "            rv = make_offspring(mu,r,generation,\n",
    "                                p1g1,p1g2,\n",
    "                                next_offspring_index,\n",
    "                                metadata,\n",
    "                                lookup,\n",
    "                                &tables)\n",
    "            handle_error_code(rv,&tables)\n",
    "            next_offspring_index+=1\n",
    "            rv = make_offspring(mu,r,generation,\n",
    "                                p2g1,p2g2,\n",
    "                                next_offspring_index,\n",
    "                                metadata,\n",
    "                                lookup,\n",
    "                                &tables)\n",
    "            # print(generation,pindex,len(lookup),len(sites))\n",
    "            assert(len(lookup)>=len(sites))\n",
    "            handle_error_code(rv,&tables)\n",
    "            next_offspring_index+=1\n",
    "        \n",
    "    if tables.nodes.next_node > 0:\n",
    "        rv=simplify(&tables,\n",
    "                    generation+1-last_gen_gc,\n",
    "                    metadata,\n",
    "                    nodes,edges,sites,mutations)\n",
    "        if rv == -1:\n",
    "            free_Tables(&tables)\n",
    "            raise RuntimeError(\"simplification error\")\n",
    "    \n",
    "    free_Tables(&tables)\n",
    "    return msprime.load_tables(nodes=nodes,edges=edges,\n",
    "                               sites=sites,mutations=mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 518 ms, total: 2.78 s\n",
      "Wall time: 2.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts = evolve(100, 1000, 100.0, 100.0, 1, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that output is invariant to how often we simplify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "767 767\n",
      "39\n",
      "767 767\n",
      "68\n",
      "767 767\n",
      "97\n",
      "767 767\n",
      "126\n",
      "767 767\n",
      "155\n",
      "767 767\n",
      "184\n",
      "767 767\n",
      "213\n",
      "767 767\n",
      "242\n",
      "767 767\n",
      "271\n",
      "767 767\n",
      "300\n",
      "767 767\n",
      "329\n",
      "767 767\n",
      "358\n",
      "767 767\n",
      "387\n",
      "767 767\n",
      "416\n",
      "767 767\n",
      "445\n",
      "767 767\n",
      "474\n",
      "767 767\n",
      "503\n",
      "767 767\n",
      "532\n",
      "767 767\n",
      "561\n",
      "767 767\n",
      "590\n",
      "767 767\n",
      "619\n",
      "767 767\n",
      "648\n",
      "767 767\n",
      "677\n",
      "767 767\n",
      "706\n",
      "767 767\n",
      "735\n",
      "767 767\n",
      "764\n",
      "767 767\n",
      "793\n",
      "767 767\n",
      "822\n",
      "767 767\n",
      "851\n",
      "767 767\n",
      "880\n",
      "767 767\n",
      "909\n",
      "767 767\n",
      "938\n",
      "767 739\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d12a83058569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mts2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msites\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for gc in range(10,1000,29):\n",
    "    print(gc)\n",
    "    ts2 = evolve(100, 1000, 100.0, 100.0, gc, 42)\n",
    "    print(len(ts.tables.sites),len(ts2.tables.sites))\n",
    "    assert(ts2.tables.nodes == ts.tables.nodes)\n",
    "    assert(ts2.tables.edges == ts.tables.edges)\n",
    "    assert(ts2.tables.sites == ts.tables.sites)\n",
    "    assert(ts2.tables.mutations == ts.tables.mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ts = evolve(1000,10000,100.0,1000.0,1000,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun -l 10 -s cumulative\n",
    "ts = evolve(1000,10000,100.0,1000.0,1000,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = msprime.unpack_bytes(ts.tables.mutations.metadata,\n",
    "                             ts.tables.mutations.metadata_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mdata:\n",
    "    md = struct.unpack('id',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to msprime\n",
    "\n",
    "In this section, we compare the distribution of outputs to msprime using [pylibseq](https://github.com/molpopgen/pylibseq), a Python interface to [libsequence](http://molpopgen.github.io/libsequence/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "import msprime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from libsequence.polytable import SimData\n",
    "from libsequence.summstats import PolySIM\n",
    "from libsequence.msprime import make_SimData\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "SummStats=namedtuple('SummStats',['S','pi','D','hprime','rmin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick tour of pylibseq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data with msprime\n",
    "ts = msprime.simulate(10,mutation_rate=1,random_seed=666)\n",
    "\n",
    "# Get it into the format expected by pylibseq\n",
    "d = make_SimData(ts)\n",
    "\n",
    "# This should look familiar! :)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object to calculate summary stats\n",
    "x = PolySIM(d)\n",
    "# Calculate a few:\n",
    "print(x.thetapi(),x.tajimasd(),x.hprime(),x.rm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "msprime_raw_data=[]\n",
    "for i in msprime.simulate(20,mutation_rate=100.0/4.0,\n",
    "                          recombination_rate=100.0/4., #100.0/4.0,\n",
    "                          num_replicates=1000,\n",
    "                          random_seed=42):\n",
    "    d = make_SimData(i)\n",
    "    ps = PolySIM(d)\n",
    "    # A little check that the two pieces of code agree\n",
    "    assert(ps.numpoly() == i.num_mutations)\n",
    "    msprime_raw_data.append(SummStats(ps.numpoly(),\n",
    "                                      ps.thetapi(),ps.tajimasd(),\n",
    "                                      ps.hprime(),ps.rm()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the forward simulations, we will use multiple Python processes via Python 3's [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html) library. The short of it is that we need a Python function to send out to different processes and return results, which will be pickled into a future back in the main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forward_sim(nreps,repid):\n",
    "    \"\"\"\n",
    "    Run our forward sim, calculate\n",
    "    a bunch of stats, and return \n",
    "    the list.\n",
    "    \"\"\"\n",
    "    # Not the best seeding scheme, \n",
    "    # but good enough for now...\n",
    "    np.random.seed(repid+1)\n",
    "    msp_rng = msprime.RandomGenerator(repid+1)\n",
    "    seeds = np.random.randint(0,1000000,nreps) * repid\n",
    "    sims = []\n",
    "    for i in range(nreps):\n",
    "        ts = evolve(1000,20000,0.0,100.0,1000,seeds[i])\n",
    "        samples = np.random.choice(2000,20,replace=False)\n",
    "        ts2 = ts.simplify(samples=samples.tolist())\n",
    "        n=msprime.NodeTable()\n",
    "        e=msprime.EdgeTable()\n",
    "        s=msprime.SiteTable()\n",
    "        m=msprime.MutationTable()\n",
    "        ts2.dump_tables(nodes=n,edges=e)\n",
    "        mutgen = msprime.MutationGenerator(\n",
    "            msp_rng, 100.0/(float(4*1000)))\n",
    "        mutgen.generate(n,e,s,m)\n",
    "        # print(len(n),len(e),len(s),len(m),n.time.max())\n",
    "        ts2=msprime.load_tables(nodes=n,edges=e,sites=s,mutations=m)\n",
    "        # print(samples)\n",
    "        # print(n.time[samples])\n",
    "        # print(s)\n",
    "        # print(m)\n",
    "        # Simplify from entire pop down\n",
    "        # to random sample of n << 2N\n",
    "        # slist = samples.tolist()\n",
    "        # slist.append(8)\n",
    "        # ts2=ts.simplify(slist)\n",
    "        # print(ts2.num_mutations)\n",
    "        # print(len(ts2.tables.nodes),\n",
    "        #      len(ts2.tables.edges),\n",
    "        #      len(ts2.tables.sites),\n",
    "        #      len(ts2.tables.mutations))\n",
    "        d=make_SimData(ts2)\n",
    "        ps=PolySIM(d)\n",
    "        sims.append(SummStats(ps.numpoly(),\n",
    "                              ps.thetapi(),\n",
    "                              ps.tajimasd(),\n",
    "                              ps.hprime(),\n",
    "                              ps.rm()))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x=run_forward_sim(1,3511)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next bit, we map our function into four separate processes.\n",
    "\n",
    "**Note:** We could use a `concurrent.futures.ThreadPoolExecutor` instead of the process pool executor.  However, some of our Cython functions rely on Python types (`list`, `dict`, etc.), meaning that the Global Interpreter Lock is a barrier to efficient concurrency.  In practice, we've found it better to take the hit of pickling between processes so that your simulations can run at 100% CPU in different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fwd_sim_data=[]\n",
    "np.random.seed(101)\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    futures = {executor.submit(run_forward_sim,250,i): i for i in range(4)}\n",
    "    for fut in concurrent.futures.as_completed(futures):\n",
    "        fn = fut.result()\n",
    "        fwd_sim_data.extend(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msprime_df = pd.DataFrame(msprime_raw_data)\n",
    "msprime_df['engine'] = ['msprime']*len(msprime_df.index)\n",
    "fwd_df = pd.DataFrame(fwd_sim_data)\n",
    "fwd_df['engine']=['forward']*len(fwd_df)\n",
    "summstats_df = pd.concat([msprime_df,fwd_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.FacetGrid(summstats_df,col=\"engine\",margin_titles=True)\n",
    "bins = np.linspace(summstats_df.pi.min(),summstats_df.pi.max(),20)\n",
    "g.map(plt.hist,'pi',bins=bins,color=\"steelblue\",lw=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fwd_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summstats_df.groupby(['engine']).agg(['mean','std']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats are clearly off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.pi,msprime_df.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.S,msprime_df.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.D,msprime_df.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(fwd_df.rmin,msprime_df.rmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
